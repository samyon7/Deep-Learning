{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRJrPYOEDLSY"
   },
   "source": [
    "<b>HAM OR SPAM IN TENSORFLOW WITH COLAB</b><br>\n",
    "--\n",
    "AUTHOR : HAMORA HADI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "  !pip install tf-nightly\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "!pip install tensorflow-datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMHwYXHXCar3"
   },
   "outputs": [],
   "source": [
    "# get data files\n",
    "TRAIN_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\"\n",
    "TEST_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_h508FEClxO"
   },
   "outputs": [],
   "source": [
    "train_messages = pd.read_csv(TRAIN_DATA_URL, sep ='\\t',names=[\"label\", \"message\"])\n",
    "test_messages = pd.read_csv(TEST_DATA_URL, sep ='\\t',names=[\"label\", \"message\"])\n",
    "\n",
    "print(\"Size of training set:\", train_messages.shape)\n",
    "print(\"Size of test set:\", test_messages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOMKywn4zReN"
   },
   "outputs": [],
   "source": [
    "train_messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npGd-lqPC9U7"
   },
   "outputs": [],
   "source": [
    "train_messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbGm4jNtDGBY"
   },
   "source": [
    "HAM=0<br>\n",
    "SPAM=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpjX2sHVC9oo"
   },
   "outputs": [],
   "source": [
    "train_messages['msg_type']= train_messages['label'].map({'ham': 0, 'spam': 1})\n",
    "train_msg = train_messages['message']\n",
    "train_labels = train_messages['msg_type'].values\n",
    "\n",
    "test_messages['msg_type']= test_messages['label'].map({'ham': 0, 'spam': 1})\n",
    "test_msg = test_messages['message']\n",
    "test_labels = test_messages['msg_type'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YdLtfmlDct5"
   },
   "source": [
    "<b>TOKENIZATION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPoz1JBKDbjh"
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "trunc_type = \"post\" \n",
    "padding_type = \"post\" \n",
    "oov_tok = \"<OOV>\"  #out of vocabulary token will be added to word index in the corpus which is used to build the model. This is used to replace out of vocabulary words during text_to_sequence calls \n",
    "vocab_size = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vS3fYSTzDrdY"
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(train_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSRsVe4SDwip"
   },
   "source": [
    "**GET THE WORD INDEX!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6QcxyZlDvmY"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qx4jp8FuD8Ax"
   },
   "source": [
    "<b>CHECK HOW MANY WORDS IN TRAINING DATA!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rURmgjlzD3mZ"
   },
   "outputs": [],
   "source": [
    "tot_words = len(word_index)\n",
    "print('No. of unique tokens in training data: %s ' % tot_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXAJhf_mEHcp"
   },
   "source": [
    "**Sequencing and Padding**<br>\n",
    "\n",
    "\n",
    "After tokenization, we represent each sentence by sequences of numbers using texts_to_sequences() from tokenizer object. Subsequently, we use pad_sequences() so that each sequence will have same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ud76ooB4EF-J"
   },
   "outputs": [],
   "source": [
    "training_seq = tokenizer.texts_to_sequences(train_msg)\n",
    "training_padded = keras.preprocessing.sequence.pad_sequences(training_seq, maxlen=max_len, \n",
    "                                                             padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(test_msg)\n",
    "test_padded = keras.preprocessing.sequence.pad_sequences(test_seq, maxlen=max_len, \n",
    "                                                             padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9C2zcw5FEGAI"
   },
   "outputs": [],
   "source": [
    "print('Shape of training tensor: ', training_padded.shape)\n",
    "print('Shape of testing tensor: ', test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FC3MHTSEWvp"
   },
   "source": [
    "<b>DENSE MODEL!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuvnjBNHEGCK"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sc-57oEkEVfx"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model_dense = tf.keras.Sequential([\n",
    "  layers.Embedding(vocab_size, embedding_dim,input_length=max_len),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dense(24, activation='relu'),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVLJF0NQExHZ"
   },
   "outputs": [],
   "source": [
    "model_dense.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt8_MuKhEwSR"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3) #stops training if validation performance doesn't improve after 3 epochs\n",
    "\n",
    "history_dense = model_dense.fit(training_padded, train_labels, epochs=num_epochs, validation_data=(test_padded,test_labels),callbacks=[early_stop], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWQtwIkMExEp"
   },
   "outputs": [],
   "source": [
    "model_dense.evaluate(test_padded, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8T_nnrLFDEU"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "metrics = pd.DataFrame(history_dense.history)\n",
    "# Rename column\n",
    "metrics.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy',\n",
    "                         'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)\n",
    "def plot_graphs1(var1, var2, string):\n",
    "    metrics[[var1, var2]].plot()\n",
    "    plt.title('Dense Model: Training and Validation ' + string)\n",
    "    plt.xlabel ('Number of epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([var1, var2])\n",
    "plot_graphs1('Training_Loss', 'Validation_Loss', 'loss')\n",
    "plot_graphs1('Training_Accuracy', 'Validation_Accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpJffZFuFtai"
   },
   "source": [
    "Now, create <b>LSTM</b>!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHRdvAJTFXLN"
   },
   "outputs": [],
   "source": [
    "model_LSTM = tf.keras.Sequential([\n",
    "  layers.Embedding(vocab_size, embedding_dim,input_length=max_len),\n",
    "  layers.LSTM(20, dropout=0.2,return_sequences=True),\n",
    "  layers.LSTM(20, dropout=0.2,return_sequences=True),\n",
    "  layers.Dense(1,activation='sigmoid')])\n",
    "\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQqpHxoVFdQh"
   },
   "outputs": [],
   "source": [
    "model_LSTM.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])\n",
    "num_epochs = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history_LSTM = model_LSTM.fit(training_padded, train_labels, epochs=num_epochs, validation_data=(test_padded,test_labels), callbacks=[early_stop], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHCJf4NVFg5S"
   },
   "outputs": [],
   "source": [
    "model_LSTM.evaluate(test_padded, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDD6rk6DF6Ny"
   },
   "outputs": [],
   "source": [
    "model_LSTM.evaluate(test_padded, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdHfCKMFGMoo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a dataframe\n",
    "metrics_LSTM = pd.DataFrame(history_LSTM.history)\n",
    "# Rename column\n",
    "metrics_LSTM.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy',\n",
    "                         'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)\n",
    "def plot_graphs2(var1, var2, string):\n",
    "    metrics_LSTM[[var1, var2]].plot()\n",
    "    plt.title('LSTM Model: Training and Validation ' + string)\n",
    "    plt.xlabel ('Number of epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([var1, var2])\n",
    "plot_graphs2('Training_Loss', 'Validation_Loss', 'loss')\n",
    "plot_graphs2('Training_Accuracy', 'Validation_Accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljLj76HHGObE"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def predict_message(pred_text):\n",
    "    prediction = []\n",
    "    new_seq = tokenizer.texts_to_sequences([pred_text])\n",
    "    padded = pad_sequences(new_seq, maxlen =max_len,\n",
    "                      padding = padding_type,\n",
    "                      truncating=trunc_type)\n",
    "    prediction_prob = model_dense.predict(padded)[0][0]\n",
    "    prediction.append(prediction_prob)\n",
    "    if prediction_prob>0.5:\n",
    "      prediction.append('spam')\n",
    "    \n",
    "    else:\n",
    "      prediction.append('ham')\n",
    "\n",
    "    return (prediction)\n",
    "\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAKB34kxGRfe"
   },
   "outputs": [],
   "source": [
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    print(prediction)\n",
    "    if prediction[1] != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"Model can predict!\")\n",
    "  else:\n",
    "    print(\"Model can't predict!\")\n",
    "  \n",
    "\n",
    "test_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tGCCWEcIJ6G"
   },
   "source": [
    "JUST THIS!<br>\n",
    "THANK YOU!<br><br>\n",
    "~HAMORA HADI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fcc_sms_text_classification.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
